{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS336 Basics Playground\n",
    "\n",
    "This notebook is for experimenting with the CS336 basics implementation.\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "Make sure to run this notebook within the uv environment. You can start it with:\n",
    "```bash\n",
    "uv run jupyter lab playground.ipynb\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 (main, Jul  8 2025, 20:55:53) [Clang 20.1.4 ]\n",
      "PyTorch: 2.6.0\n",
      "NumPy: 2.3.2\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Import basic modules to verify environment\n",
    "import sys\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, theta: float, d_k: int, max_seq_len: int, device: torch.device | None = None):\n",
    "        super().__init__()\n",
    "        rotation_matrices = []\n",
    "        dtype = torch.float32\n",
    "        for i in range(max_seq_len):\n",
    "            rotation_values = torch.tensor([i / (math.pow(theta, (2 * (k // 2)) / float(d_k))) for k in range(d_k)], dtype=dtype)\n",
    "            print(rotation_values)\n",
    "            cos_values = torch.cos(rotation_values)\n",
    "            mask = torch.arange(rotation_values.shape[0], dtype=dtype) % 2 == 0\n",
    "            sin_values = torch.sin(torch.where(mask, rotation_values, 0))[:-1]\n",
    "            rotation_matrices.append(torch.diag(cos_values) + torch.diag(sin_values, diagonal=-1) + torch.diag(-sin_values, diagonal=1))\n",
    "        self.register_buffer('rotary_matrix', torch.stack(rotation_matrices, dim=0).to(device))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, token_positions: torch.Tensor) -> torch.Tensor:\n",
    "        rotary_matrices = self.rotary_matrix[token_positions]\n",
    "        return einsum(rotary_matrices, x, '... seq_len d_k d_k, ... seq_len d_k -> ... seq_len d_k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([1.0000, 1.0000, 0.7937, 0.7937, 0.6300, 0.6300])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RotaryPositionalEmbedding.forward() missing 1 required positional argument: 'token_positions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m rope = RotaryPositionalEmbedding(\u001b[32m2\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m      2\u001b[39m rope.rotary_matrix\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mrope\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: RotaryPositionalEmbedding.forward() missing 1 required positional argument: 'token_positions'"
     ]
    }
   ],
   "source": [
    "rope = RotaryPositionalEmbedding(2, 6, 2)\n",
    "rope.rotary_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryPositionalEmbeddingCorrect(nn.Module):\n",
    "    def __init__(self, theta: float, d_k: int, max_seq_len: int, device: torch.device | None = None):\n",
    "        super().__init__()\n",
    "        dtype = torch.float32\n",
    "\n",
    "        # positions: [0, 1, ..., max_seq_len-1]\n",
    "        positions = torch.arange(max_seq_len, device=device, dtype=dtype).unsqueeze(1)\n",
    "\n",
    "        # pair indices: [0, 1, ..., d_k/2 - 1]\n",
    "        pair_indices = torch.arange(0, d_k // 2, device=device, dtype=dtype)\n",
    "\n",
    "        # inverse frequencies theta^{-2i/d_k}\n",
    "        inv_freq = theta ** (-2.0 * pair_indices / float(d_k))\n",
    "        \n",
    "\n",
    "        # angles = position * inv_freq  -> shape: (max_seq_len, d_k/2)\n",
    "        angles = positions * inv_freq\n",
    "        print(angles)\n",
    "        cos = torch.cos(angles)\n",
    "        sin = torch.sin(angles)\n",
    "\n",
    "        # Cache trig tables per position for each pair\n",
    "        self.register_buffer('cos_table', cos)\n",
    "        self.register_buffer('sin_table', sin)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, token_positions: torch.Tensor) -> torch.Tensor:\n",
    "        # Fetch per-position cos/sin for each feature pair\n",
    "        cos_table_t = cast(torch.Tensor, self.cos_table)\n",
    "        sin_table_t = cast(torch.Tensor, self.sin_table)\n",
    "        cos = cos_table_t[token_positions].to(dtype=x.dtype)\n",
    "        sin = sin_table_t[token_positions].to(dtype=x.dtype)\n",
    "\n",
    "        x_even = x[..., 0::2]\n",
    "        x_odd = x[..., 1::2]\n",
    "\n",
    "        rotated_even = x_even * cos - x_odd * sin\n",
    "        rotated_odd = x_even * sin + x_odd * cos\n",
    "\n",
    "        # Interleave even/odd back into last dimension\n",
    "        out = torch.empty_like(x)\n",
    "        out[..., 0::2] = rotated_even\n",
    "        out[..., 1::2] = rotated_odd\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.7937, 0.6300]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000],\n",
       "        [0.5403, 0.7012, 0.8081]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rope = RotaryPositionalEmbeddingCorrect(2, 6, 2)\n",
    "rope.cos_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [0.8415, 0.8415]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rope.sin_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
